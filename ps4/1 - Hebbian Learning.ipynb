{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "source": [
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "outputs": [],
   "source": [
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "One of the simplest neural network learning algorithms is Hebbian\n",
    "learning, in which the weight between two nodes is increased when\n",
    "those nodes take on the same value, and decreased when they take on\n",
    "different values. If ${\\bf x} = (x_1, \\ldots x_n)^T$ and\n",
    "${\\bf y} = (y_1, \\ldots, y_m)^T$ are $n \\times 1$ and $m \\times 1$\n",
    "vectors representing the inputs and outputs to a neural network\n",
    "respectively, the weights of the neural network can be expressed in a\n",
    "$m \\times n$ matrix ${\\bf W}$. The networks predicted output\n",
    "$\\mathbf{\\hat{y}}$ is then:\n",
    "\n",
    "\\begin{equation}      \n",
    "\\mathbf{\\hat{y}}  = \\mathbf{Wx}\n",
    "\\end{equation}\n",
    "\n",
    "We train the neural network by providing it with a set of input-output\n",
    "pairs, $({\\bf x},{\\bf y})$. Hebbian learning adjusts the weights using\n",
    "the following equation for each input-output pair:\n",
    "\n",
    "\\begin{equation}         \n",
    "\\Delta\\mathbf{W} = \\eta \\mathbf{y}\\mathbf{x}^{T}\n",
    "\\end{equation} \n",
    "        \n",
    "In other words, the change in the weight matrix $\\mathbf{W}$ is determined by\n",
    "the outer product of the output and input vectors, multiplied by the\n",
    "learning rate $\\eta$. Then, the updated weight matrix equals the old\n",
    "weight matrix plus $\\Delta\\mathbf{W}$.\n",
    "\n",
    "\\begin{equation}         \n",
    "\\mathbf{\\hat{W}} = \\mathbf{W} + \\Delta \\mathbf{W}\n",
    "\\end{equation} \n",
    "\n",
    "Another way to think about this is that each weight $w_{ij}$, which connects input neuron $j$ to output neuron $i$, is updated based on the correlation between their values:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Delta{w_{ij}} = w_{ij} + \\eta y_i x_j\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "The Hebb rule was inspired by people thinking about how neuronal interactions may enable learning, and was confirmed by experiments many years later. It is, therefore, a good example of how considering a problem at the algorithmic level can guide the investigation of the implementational, and, vice versa, how discoveries at the implementational level can confirm thoughts about the suitability of algorithmic descriptions of processes.\n",
    "\n",
    "Read more about the motivation and formulation behind the Hebb rule here: https://en.wikipedia.org/wiki/Hebbian_theory\n",
    "\n",
    "Independent of its neuronal interpretations and basis, the Hebb rule forms the basis of many systems for *unsupervised* learning, as it organizes networks based solely on the statistics of the input, rather than any signal for a teacher.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "\n",
    "## Part A (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Assume we want to learn what noises animals make based on their\n",
    "appearance. We might list four input features: chasing sticks, liking water, having whiskers, and being furry, and then represent dogs with\n",
    "${\\bf x}_{\\rm dog} = ( 1, 1, 1, 1)^T$ and cats with\n",
    "${\\bf x}_{\\rm cat} = (-1,-1,1,1)^T$. Likewise, we could have four\n",
    "output features: hissing, barking, neighing, and growling, with\n",
    "${\\bf y}_{\\rm dog} = (-1,1,-1,1)^T$ and\n",
    "${\\bf y}_{\\rm cat} = (1, -1 -1, 1)^T$. Then\n",
    "$(\\mathbf{x}_{\\rm dog},\\mathbf{y}_{\\rm dog})$ would be one the\n",
    "input-output pair for dogs. Note that 1 indicates a logical <code>TRUE</code> and -1 indicates a logical <code>FALSE</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "inputFeatures = ['chases sticks', 'likes water','whiskers','furry']\n",
    "outputFeatures = ['hisses','barks','neighs','growls']\n",
    "\n",
    "xDog = np.array([ 1., 1., 1., 1. ])\n",
    "xCat = np.array([ -1., -1., 1., 1. ])\n",
    "\n",
    "yDog =  np.array([ -1., 1., -1., 1. ])\n",
    "yCat = np.array([ 1., -1., -1., 1. ])\n",
    "\n",
    "trainingInputs = np.column_stack((xDog, xCat))\n",
    "trainingOutputs = np.column_stack((yDog, yCat))\n",
    "\n",
    "W = np.zeros((len(xDog),len(xDog)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Complete the function definition <code>updateWeights</code> so that it takes the current weight matrix $\\mathbf{W}$, a matrix of training data inputs, and a matrix of training data outputs as parameters and returns a matrix with the updated weights using Hebbian learning on the given\n",
    "training data.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "The matrix of training data inputs should have training instances as\n",
    "its columns. For example, if there were two training instances,\n",
    "$\\mathbf{x}_{\\rm dog}$ and $\\mathbf{x}_{\\rm cat}$, the matrix would\n",
    "have two columns:\n",
    "$\\left[\\mathbf{x}_{\\rm dog},\\mathbf{x}_{\\rm cat}\\right]$. The matrix\n",
    "of training data outputs should have two columns corresponding to\n",
    "output instances:\n",
    "$\\left[\\mathbf{y}_{\\rm dog},\\mathbf{y}_{\\rm cat}\\right]$. The learning rate $\\eta$ is set at $.25$ inside <code>updateWeights</code> as a default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1cbc8e2e0c23cc90713f8893fb025fac",
     "grade": false,
     "grade_id": "updateWeights",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def updateWeights(W, trainingInputs, trainingOutputs, eta = 0.25):\n",
    "    \"\"\"\n",
    "    Updates the current weight matrix W using Hebbian learning.\n",
    "    \n",
    "    Hint: your solution can be done in a single line of code, \n",
    "    including the return statement.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    W: the trained weight matrix\n",
    "    trainingInputs:  a matrix where each column represents a set of \n",
    "        input features\n",
    "    trainingOutputs: a matrix where each column represents a set of \n",
    "        output features\n",
    "    eta: the learning rate, set at 0.25 by default    \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    a matrix with the updated weight matrix after the network has seen \n",
    "        the given training data.\n",
    "\n",
    "    \"\"\"\n",
    "    return W + (eta * np.dot(trainingOutputs, trainingInputs.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "[[-0.5 -0.5  0.   0. ]\n",
      " [ 0.5  0.5  0.   0. ]\n",
      " [ 0.   0.  -0.5 -0.5]\n",
      " [ 0.   0.   0.5  0.5]]\n"
     ]
    }
   ],
   "source": [
    "updatedW = updateWeights(W,trainingInputs,trainingOutputs)\n",
    "print(W)\n",
    "print(updatedW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# add your own test cases here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "95993fe125c36b6335c688b6959ad4c1",
     "grade": true,
     "grade_id": "test_updateWeights",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Check that `updateWeights` produces expected output.\"\"\"\n",
    "from nose.tools import assert_equal\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "testW0 = np.zeros((4,4))\n",
    "testInputs1 = np.array([[1, -1, 1],[1, -1, 1],[1, 1, 1],[1, 1, 1]])\n",
    "testOutputs1 = np.array([[-1, 1, 1],[1, -1, 1],[-1, -1, 1],[1, 1, 1]])\n",
    "\n",
    "testW1 = updateWeights(testW0, testInputs1[:,[0,1]],testOutputs1[:,[0,1]])\n",
    "\n",
    "\"\"\"Confirm that the output is an array\"\"\" \n",
    "assert(isinstance(testW1, np.ndarray))\n",
    "\n",
    "\"\"\"Check if dimensions are the same as the original weights\"\"\" \n",
    "assert_equal(testW1.shape, (4, 4))\n",
    "\n",
    "\"\"\"Check if weight matrix sums to 0, if trained on first two examples\"\"\" \n",
    "assert_equal(testW1.sum(),0)\n",
    "\n",
    "testW2 = updateWeights(testW0, testInputs1, testOutputs1)\n",
    "\n",
    "\"\"\"Check if weight matrix sums to 4, if trained on all three examples\"\"\" \n",
    "assert_equal(testW2.sum(),4)\n",
    "\n",
    "testW3 = updateWeights(np.zeros((3,3)), testInputs1[0:3,], testOutputs1[0:3,])\n",
    "\n",
    "\"\"\"Check if dimensions are the same as the original weights\"\"\" \n",
    "assert_equal(testW3.shape, (3, 3))\n",
    "\n",
    "\"\"\"Check if the weight matrix is correct: Input 1\"\"\" \n",
    "testW4 = updateWeights(testW0, testInputs1,testOutputs1)\n",
    "assert_allclose(testW4,np.array(\n",
    "       [[-0.25, -0.25,  0.25,  0.25],\n",
    "       [ 0.75,  0.75,  0.25,  0.25],\n",
    "       [ 0.25,  0.25, -0.25, -0.25],\n",
    "       [ 0.25,  0.25,  0.75,  0.75]]))\n",
    "\n",
    "\"\"\"Check if the weight matrix is correct: Input 2\"\"\" \n",
    "test_xDog = np.array([ 1., 1., 1., 1. ])\n",
    "test_xCat = np.array([ -1., -1., 1., 1. ])\n",
    "test_yDog =  np.array([ -1., 1., -1., 1. ])\n",
    "test_yCat = np.array([ 1., -1., -1., 1. ])\n",
    "\n",
    "testInputs2 = np.column_stack((test_xDog, test_xCat))\n",
    "testOutputs2 = np.column_stack((test_yDog, test_yCat))\n",
    "\n",
    "testW5 = updateWeights(testW0, testInputs2,testOutputs2)\n",
    "assert_allclose(testW5,np.array(\n",
    "       [[-0.5, -0.5,  0. ,  0. ],\n",
    "       [ 0.5,  0.5,  0. ,  0. ],\n",
    "       [ 0. ,  0. , -0.5, -0.5],\n",
    "       [ 0. ,  0. ,  0.5,  0.5]]))\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "\n",
    "## Part B (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Calculate the network's predicted output\n",
    "$\\mathbf{\\hat{y}}$ for inputs ${\\bf x}_{\\rm dog}$ and\n",
    "${\\bf x}_{\\rm cat}$. Complete the function definition in <code>getPredictions</code>, which takes ${\\bf x}_{\\rm dog}$, ${\\bf x}_{\\rm cat}$, and <code>updatedW</code> as parameters and returns a dictionary with the predicted binary feature arrays for cat (for the key \n",
    "<code>yhatCat</code>) and dog (<code>yhatDog</code>).\n",
    "\n",
    "**Hint:** To double-check that your code is functioning correctly,\n",
    "these predicted outputs should be equal to their respective training\n",
    "data outputs because the training data vectors are orthogonal.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "281b5037a48f3e8d0ea3eb1a743924ee",
     "grade": false,
     "grade_id": "getPredictions",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def getPredictions(xDog, xCat, updatedW):   \n",
    "    \"\"\"\n",
    "    Gets predicted binary feature vectors for cats and dogs\n",
    "    \n",
    "    Hint: your solution can be done in one or two lines of code, \n",
    "    including the return statement. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    xDog: the feature vector representing the input features for dog\n",
    "    xCat: the feature vector representing the input features for cat\n",
    "    updatedW: the weight matrix after training\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    a dictionary with two key-value pairs\n",
    "        'yhatCat' ; the predicted binary features for cat \n",
    "        'yhatDog' ; the predicted binary features for dog \n",
    "\n",
    "    \"\"\"    \n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    return {\"yhatDog\": np.dot(updatedW, xDog), \"yhatCat\" : np.dot(updatedW, xCat)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yhatDog': array([-1.,  1., -1.,  1.]), 'yhatCat': array([ 1., -1., -1.,  1.])}\n"
     ]
    }
   ],
   "source": [
    "predictions = getPredictions(xDog, xCat, updatedW)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# add your own test cases here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "281a5dc6374de442517b0557b177b434",
     "grade": true,
     "grade_id": "test_getPredictions",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Confirm that the output is an array\"\"\" \n",
    "testPredictions = getPredictions(test_xDog, test_xCat, testW5)\n",
    "assert_equal(type(testPredictions), dict)\n",
    "\n",
    "\"\"\"Check if the keys are defined\"\"\" \n",
    "assert_equal('yhatCat' in testPredictions and 'yhatDog' \\\n",
    "    in testPredictions, True)\n",
    "\n",
    "\"\"\"Check that the vectors are binary, with 1 and -1\"\"\"\n",
    "assert(testPredictions['yhatCat'].prod() == 1 or  \\\n",
    "       testPredictions['yhatCat'].prod() == -1)\n",
    "assert(testPredictions['yhatDog'].prod() == 1 or \\\n",
    "       testPredictions['yhatDog'].prod() == -1)\n",
    "\n",
    "\"\"\"Check that the vectors are of the right length\"\"\"\n",
    "assert_equal(len(testPredictions['yhatCat']), 4)\n",
    "assert_equal(len(testPredictions['yhatDog']), 4)\n",
    "\n",
    "\"\"\"Check that the predicted output is the same as the true output\"\"\"\n",
    "assert(all(testPredictions['yhatCat'] == test_yCat))\n",
    "assert(all(testPredictions['yhatDog'] == test_yDog))\n",
    "\n",
    "\n",
    "\"\"\"Check that the predicted output for arbitrary input\"\"\"\n",
    "testInput1 = np.array([-1, -1, -1, -1])\n",
    "testInput2 = np.array([1, 1, -1, -1])\n",
    "testPredictions2 = getPredictions(testInput1, testInput2, updatedW)\n",
    "assert_allclose(testPredictions2['yhatCat'], \\\n",
    "                np.array([-1.,  1.,  1., -1.]))\n",
    "assert_allclose(testPredictions2['yhatDog'], \\\n",
    "                np.array([ 1., -1.,  1., -1.]))\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "## Part C (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Now, imagine you saw an animal that was definitely furry and had\n",
    "whiskers, but you weren't sure about whether it liked water or chased\n",
    "sticks. We could represent the features of this animal as the (convex) combination:\n",
    "\\begin{equation}\n",
    "{\\bf x}_{\\rm unknown} = \\alpha {\\bf x}_{\\rm dog} + (1-\\alpha) {\\bf x}_{\\rm cat}\n",
    "\\end{equation}\n",
    "for some value of $\\alpha$ between $0$ and $1$. In other words, because we aren't certain of certain features in the ${\\bf x}_{\\rm unknown}$ vector, we can use various values of $\\alpha$ to quantify our uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Using the value of ${\\bf W}$ computed in Part A, what is the\n",
    "predicted network output $\\mathbf{\\hat{y}}$ for different inputs\n",
    "${\\bf x}_{\\rm unknown}$ with $\\alpha = 0.2$, $0.5$,\n",
    "and $0.8$? Complete the function <code>getWeightedPredictions</code>, and return a dictionary that stores these predictions in the keys\n",
    "<code>yhatAnimalX2</code>, <code>yhatAnimalX5</code>, and\n",
    "<code>yhatAnimalX8</code>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9cfe679186652671b74e128c37987182",
     "grade": false,
     "grade_id": "getWeightedPredictions",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def getWeightedPredictions(xDog, xCat, updatedW):   \n",
    "    \"\"\"\n",
    "    Get predicted binary feature vectors given a series of part-cat, \n",
    "    part-dog inputs, corresponding to alpha values of .2, .5 and .8 \n",
    "    \n",
    "    Hint: your solution can be done in about three lines of code, \n",
    "    including the return statement. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    xDog: the feature vector representing the input features for dog\n",
    "    xCat: the feature vector representing the input features for cat\n",
    "    updatedW: the weight matrix after training\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    a dictionary with two key-value pairs\n",
    "        'yhatAnimalX2' ; the predicted binary features when alpha = .2 \n",
    "        'yhatAnimalX5' ; the predicted binary features when alpha = .5 \n",
    "        'yhatAnimalX8' ; the predicted binary features when alpha = .8 \n",
    "\n",
    "    \"\"\"    \n",
    "    yhatAnimalX2 = (0.2 * xDog) + (1 - 0.2)* xCat\n",
    "    yhatAnimalX5 = (0.5 * xDog) + (1 - 0.5)* xCat\n",
    "    yhatAnimalX8 = (0.8 * xDog) + (1 - 0.8)* xCat\n",
    "    return {\"yhatAnimalX2\": np.dot(updatedW, yhatAnimalX2), \n",
    "            \"yhatAnimalX5\": np.dot(updatedW, yhatAnimalX5), \n",
    "            \"yhatAnimalX8\": np.dot(updatedW, yhatAnimalX8)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yhatAnimalX2': array([ 0.6, -0.6, -1. ,  1. ]), 'yhatAnimalX5': array([ 0.,  0., -1.,  1.]), 'yhatAnimalX8': array([-0.6,  0.6, -1. ,  1. ])}\n"
     ]
    }
   ],
   "source": [
    "weightedPredictions = getWeightedPredictions(xDog, xCat, updatedW)\n",
    "print(weightedPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# add your own test cases here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "49efe59ccfc5e86b740ced960bfe476f",
     "grade": true,
     "grade_id": "test_getWeightedPredictions",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "testWeightedPredictions = getWeightedPredictions(test_xDog, test_xCat,\\\n",
    "    testW5)\n",
    "\n",
    "\"\"\"Confirm that the output is an array\"\"\" \n",
    "assert_equal(type(testWeightedPredictions), dict)\n",
    "\n",
    "\"\"\"Check if the keys are defined\"\"\" \n",
    "assert_equal('yhatAnimalX2' in testWeightedPredictions and \\\n",
    "             'yhatAnimalX5' in testWeightedPredictions and \\\n",
    "             'yhatAnimalX8' in testWeightedPredictions , True)\n",
    "\n",
    "\"\"\"Check that the vectors are of the right length\"\"\"\n",
    "assert_equal(len(testWeightedPredictions['yhatAnimalX2']), 4)\n",
    "assert_equal(len(testWeightedPredictions['yhatAnimalX5']), 4)\n",
    "assert_equal(len(testWeightedPredictions['yhatAnimalX8']), 4)\n",
    "\n",
    "\"\"\"Check the output values for .2, .5, and .8\"\"\"\n",
    "assert_allclose(testWeightedPredictions['yhatAnimalX2'], \\\n",
    "    np.array([ 0.6, -0.6, -1. ,  1. ]))\n",
    "assert_allclose(testWeightedPredictions['yhatAnimalX5'], \\\n",
    "    np.array([ 0.,  0., -1.,  1.]))\n",
    "assert_allclose(testWeightedPredictions['yhatAnimalX8'], \\\n",
    "    np.array([-0.6,  0.6, -1. ,  1. ]))\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Part D (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Interpret these predictions in terms of the noises the animal might\n",
    "make. This subquestion is worth **1.5 points**, so give a detailed answer, stating your predictions and interpreting them fully.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "992b21f4406b428f2678d89c2c32d492",
     "grade": true,
     "grade_id": "part_d_1",
     "locked": false,
     "points": 1.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "For animal with alpha value = 0.2, the prediction corresponds to [0.6, -0.6, -1, 1]. This means that this animal has a high chance that it hisses, high chance that it does *not* bark, does not neigh, and growls. The predictions definitely make sense to me, because given the 0.2 alpha value here, if the animal was 20% Dog and 80% Cat, I believe the animal would have a high chance to hiss, most likely not bark, not neigh, and growl.  \n",
    "\n",
    "For animal with alpha value = 0.5, the prediction corresponds to [0, 0, -1, 1]. This means that this animal then has a 50% chance of hissing, 50% chance of barking, does not neigh, and growls. Given the alpha value here, the animal is ambiguously either 50% dog or 50% cat. Therefore, I think the predictions are entirely accurate because the animal should have a 50% chance of hissing, 50% chance of barking, not neigh, and 100% chance of growling (because both animals exhibit this feature). \n",
    "\n",
    "For animal with alpha value = 0.8, the prediction corresponds to [-0.6, 0.6, -1, 1.]. This means then that this animal has a very likeley chance to *not* hiss, high likeley chance that it barks, does not neigh, and growls. This animal would be 80% dog, and 20% cat given the alpha value, so the predictions the neural network made here are fairly good. I think the chance of not hissing here would be right around the hissing trait for an 80% dog animal as with the same on the barking. The predictions are entirely accurate in my book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "How does the kind of solution the neural network produces differ\n",
    "from the kind of thing we might expect from an account based on rules\n",
    "and symbols? (**0.5 points**)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b6be225aa5430d77a47699a91b14ff7a",
     "grade": true,
     "grade_id": "part_d_2",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "The solution from the neural network is continous rather than discrete based on an account comprised of rules and symbols. Therefore, it gives a better prediction given the available data and makes its guesses with a non-binary approach, which makes it much better at guessing ambiguous inputs (animals with certain percentage of dog-like and cat-like features in this case). The rules and symbols approach would be less apt to take into account the fluidity between the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "Before turning this problem in remember to do the following steps:\n",
    "\n",
    "1. **Restart the kernel** (Kernel$\\rightarrow$Restart)\n",
    "2. **Run all cells** (Cell$\\rightarrow$Run All)\n",
    "3. **Save** (File$\\rightarrow$Save and Checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "source": [
    "<div class=\"alert alert-danger\">After you have completed these three steps, ensure that the following cell has printed \"No errors\". If it has <b>not</b> printed \"No errors\", then your code has a bug in it and has thrown an error! Make sure you fix this error before turning in your problem set.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors!\n"
     ]
    }
   ],
   "source": [
    "print(\"No errors!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
