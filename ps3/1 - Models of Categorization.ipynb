{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "source": [
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "outputs": [],
   "source": [
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-warning\"><b>N.B.: </b> This notebook has three sections that together make up half the problem set. Budget your time accordingly!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "The inhabitants of the planet Boton love pushing buttons. There are many kinds of buttons on Boton: red buttons, blue buttons, big buttons, small buttons. In fact, there are four dimensions along which buttons vary:\n",
    "\n",
    "![](images/concepts.png)\n",
    "\n",
    "Not all buttons do the same thing when pushed. Some are harmless, but others are dangerous and self-destruct. As young Botonans grow up, they are taught which buttons are safe to push and which are unsafe. Unfortunately, there are no hard-and-fast rules about which buttons are safe or unsafe, so young Botonans must develop a scheme for categorizing the buttons. For example, a Botonan might observe the following:\n",
    "<a name=\"exemplars\"></a>\n",
    "\n",
    "![](images/exemplars.png)\n",
    "\n",
    "Clearly, it's not enough to say that all the blue buttons are safe because there is at least one blue button known to be unsafe. So, how do the Botonans determine which buttons are safe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "## Context Model: Part A (0.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "As a cognitive scientist, you know a few different models of categorization that have been proposed. For example, you might remember the *context model* described by Medin and Schaffer (1978). The context model is an exemplar model: the probability that a stimulus is assigned to a category is based on its similarity to all the exemplars in that category.\n",
    "\n",
    "To use the context model, we represent each stimulus (button) as a vector. For example, we can represent a big square blue textured button as $\\mathbf{x}=[1, 0, 1, 1]$. Similarly, we can represent the stimulus which is small red cicular textured button as $\\mathbf{x}=[0, 1, 0, 1]$. Given this representation, we can now define a similarity function.\n",
    "\n",
    "> <a name=\"eq:similarity\"></a>The similarity $\\mathbb{S}$ of one stimulus $\\mathbf{x}$ to another stimulus $\\mathbf{y}$ is given by the following set of equations:\n",
    ">\n",
    "> $$\n",
    "\\begin{align*}\n",
    "\\mathbb{S}(\\mathbf{x}, \\mathbf{y}) &= \\prod_{i = 1}^m s(x_i, y_i)=s(x_1, y_1)\\cdot{}s(x_2, y_2)\\cdot{}\\ldots{}\\cdot{}s(x_m, y_m)\\\\\n",
    "s(x_i, y_i) &= \\left\\{\n",
    "\\begin{array}{rl} 1 & \\text{if } x_{i} = y_{i} \\\\\n",
    "   \\theta & \\text{if } x_{i} \\neq y_{i}\\end{array}\\right.\n",
    "   \\end{align*}\n",
    "$$\n",
    ">\n",
    "> where $\\theta$ is a constant.\n",
    "\n",
    "(Remember that $\\Pi$ is like $\\Sigma$, except that you multiply the terms together instead of summing them. For example, $\\prod_{k=1}^5{k} = 1 \\cdot 2 \\cdot 3 \\cdot 4 \\cdot 5 = 5! = 120$. Or, if $\\mathbf{v}=[4,1,2]$ then, $\\prod_{i=1}^3{v_i}=4 \\cdot 1 \\cdot 2 = 8$.)\n",
    "\n",
    "So, if one stimulus is $\\mathbf{x}=[1, 0, 1, 1]$ and the other is $\\mathbf{y}=[0, 1, 1, 0]$, then we have:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbb{S}(\\mathbf{x}, \\mathbf{y}) &= \\prod_{i=1}^4 s(x_i, y_i) \\\\\n",
    "&= s(x_1, y_1) \\cdot{} s(x_2, y_2) \\cdot{} s(x_3, y_3) \\cdot{} s(x_4, y_4) \\\\\n",
    "&= \\theta \\cdot{} \\theta \\cdot{} 1 \\cdot{} \\theta \\\\\n",
    "&= \\theta^3\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Complete the function `calculate_similarity` to calculate the similarity $\\mathbb{S}(\\mathbf{x}, \\mathbf{y})$ between two stimuli (as defined in the [similarity equation](#eq:similarity)).</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "42b5f9650074de12fe860e0cf5a0e87c",
     "grade": false,
     "grade_id": "calculate_similarity",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calculate_similarity(x, y, theta=0.1):\n",
    "    \"\"\"Calculates the similarity between a stimulus x and a \n",
    "    stimulus y, where similarity is defined as:\n",
    "    \n",
    "        S(x, y) = s(x_1, y_1) * s(x_2, y_2) * ... * s(x_m, y_m)\n",
    "    \n",
    "    and:\n",
    "    \n",
    "        s(x_i, y_i) = 1 if x_i == y_i, theta otherwise\n",
    "        \n",
    "    Note: your solution can be done in one line of code, including \n",
    "    the return statement. Think about how many times you need to \n",
    "    multiply theta with itself. How can you easily compute this \n",
    "    number?\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : numpy arrays with shape (m,)\n",
    "        The stimuli to compute similarity between\n",
    "    theta : (optional) float\n",
    "        A parameter to the similarity function. When the function is\n",
    "        called without theta having been specified, it defaults to 0.1.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float : the similarity between x and y\n",
    "    \n",
    "    \"\"\"\n",
    "    n = 0\n",
    "    sim = []\n",
    "    while n < len(x):\n",
    "        if x[n] == y[n]:\n",
    "            sim.append(1)\n",
    "        else:\n",
    "            sim.append(theta)\n",
    "        n = n+1\n",
    "    return np.prod(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Verify that your function works on the example we worked out above (is the answer it returns equivalent to $\\theta^3$?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S(x, y) = 0.0010000000000000002\n",
      "S(x, y, theta=0.3) = 0.027\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 0, 1, 1])\n",
    "y = np.array([0, 1, 1, 0])\n",
    "print(\"S(x, y) = {}\".format(calculate_similarity(x, y)))\n",
    "print(\"S(x, y, theta=0.3) = {}\".format(calculate_similarity(x, y, theta=0.3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# add your own test cases here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6d350e910e2482ccc756493ce912e9c8",
     "grade": true,
     "grade_id": "test_calculate_similarity",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Check that calculate_similarity works correctly.\"\"\"\n",
    "\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "x = np.ones(8)\n",
    "y = np.zeros(8)\n",
    "assert_allclose(calculate_similarity(x, x), 1.0)\n",
    "assert_allclose(calculate_similarity(x, y), 1e-08)\n",
    "assert_allclose(calculate_similarity(x, y, theta=2.0), 256.0)\n",
    "assert_allclose(calculate_similarity(x, y, theta=0.47), 0.002381128666176099)\n",
    "assert_allclose(calculate_similarity(x, y, theta=1), 1)\n",
    "assert_allclose(calculate_similarity(x, y, theta=1.2), 4.2998169599999985)\n",
    "\n",
    "x = np.array([1, 0, 1, 0])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "assert_allclose(calculate_similarity(x, y), 0.01)\n",
    "assert_allclose(calculate_similarity(x, y, theta=0.2), 0.04)\n",
    "assert_allclose(calculate_similarity(x, y, theta=0.3), 0.09)\n",
    "assert_allclose(calculate_similarity(x, y, theta=0.47), 0.22089999999999999)\n",
    "assert_allclose(calculate_similarity(x, y, theta=1), 1)\n",
    "assert_allclose(calculate_similarity(x, y, theta=1.2), 1.44)\n",
    "\n",
    "x = np.array([0, 1, 1, 1, 0, 0, 0, 0, 0, 1])\n",
    "y = np.array([1, 1, 1, 0, 0, 1, 0, 1, 1, 0])\n",
    "assert_allclose(calculate_similarity(x, y), 1e-6)\n",
    "assert_allclose(calculate_similarity(x, y, theta=0.2), 6.4e-5)\n",
    "assert_allclose(calculate_similarity(x, y, theta=0.3), 0.0007289999999999998)\n",
    "assert_allclose(calculate_similarity(x, y, theta=0.47), 0.010779215328999996)\n",
    "assert_allclose(calculate_similarity(x, y, theta=1), 1)\n",
    "assert_allclose(calculate_similarity(x, y, theta=1.2), 2.9859839999999993)\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "\n",
    "## Context Model: Part B (1.75 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Now that we have defined the similarity between two stimuli, we can take a look at the equation for the context model. In the definition below, you can think of category $A$ as being the *safe buttons*, and category $B$ as being the *unsafe buttons*.\n",
    "\n",
    "> <a name=\"eq:context-model\"></a>The context model, which gives the probability that a novel stimulus $\\mathbf{x}$ belongs to category $A$ (as opposed to category $B$) is given by:\n",
    ">\n",
    "> $$\n",
    "P(A|\\mathbf{x}) = \\frac{\\sum_{\\mathbf{a} \\in A} \\mathbb{S}(\\mathbf{x}, \\mathbf{a})}{\\sum_{\\mathbf{a} \\in A} \\mathbb{S}(\\mathbf{x}, \\mathbf{a})+ \\sum_{\\mathbf{b} \\in B} \\mathbb{S}(\\mathbf{x}, \\mathbf{b})}\n",
    "$$\n",
    ">\n",
    "> where $\\sum_{\\mathbf{a} \\in A} \\mathbb{S}(\\mathbf{x}, \\mathbf{a})$ is the sum over the similarity of $\\mathbf{x}$ to all exemplars $\\mathbf{a}$ in category $A$, and $\\sum_{\\mathbf{b} \\in B} \\mathbb{S}(\\mathbf{x}, \\mathbf{b})$ is the sum over the similarity of $\\mathbf{x}$ to all exemplars $\\mathbf{b}$ in category $B$.\n",
    "\n",
    "Note that because $P(A|\\mathbf{x})$ is a probability, we can easily compute from it the probability that $\\mathbf{x}$ belongs to category $B$. The stimulus *must* belong to one of the two categories, thus $P(B|\\mathbf{x})=1-P(A|\\mathbf{x})$.\n",
    "\n",
    "Let's work through an example of this. Suppose there is one test stimulus $\\mathbf{x} = [1, 0, 1]$, and four exemplars: $\\mathbf{a}_1=[0, 0, 0]$ and $\\mathbf{a}_2=[0, 0, 1]$ (which have category labels of $A$) and $\\mathbf{b}_1=[1, 1, 1]$ and $\\mathbf{b}_2=[0, 1, 1]$ (which have category labels of $B$). Then:\n",
    "\n",
    "$$\n",
    "P(A|\\mathbf{x}) = \\frac{\\sum_{\\mathbf{a}\\in A} \\mathbb{S}(\\mathbf{x}, \\mathbf{a})}{\\sum_{\\mathbf{a}\\in A} \\mathbb{S}(\\mathbf{x}, \\mathbf{a}) + \\sum_{\\mathbf{b}\\in B} \\mathbb{S}(\\mathbf{x}, \\mathbf{b})}=\\frac{\\mathbb{S}(\\mathbf{x}, \\mathbf{a}_1) + \\mathbb{S}(\\mathbf{x}, \\mathbf{a}_2)}{\\mathbb{S}(\\mathbf{x}, \\mathbf{a}_1) + \\mathbb{S}(\\mathbf{x}, \\mathbf{a}_2) + \\mathbb{S}(\\mathbf{x}, \\mathbf{b}_1) + \\mathbb{S}(\\mathbf{x}, \\mathbf{b}_2)}\n",
    "$$\n",
    "\n",
    "where $\\mathbb{S}$ is the [similarity function](#eq:similarity) that we defined above and implemented in `calculate_similarity`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Write code that uses your function `calculate_similarity` to implement a version of the context model (i.e., computes the [context model equation](#eq:context-model)). Complete the function `context_model` with your solution.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a09f86d77a6a5e737de7d87fab61fa9b",
     "grade": false,
     "grade_id": "context_model",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def context_model(test_stimuli, exemplars, exemplar_categories, theta=0.1):\n",
    "    \"\"\"Computes the probability that each test stimulus belongs to \n",
    "    category A.\n",
    "    \n",
    "    Note: your solution can be done in 7 lines of code, including \n",
    "    the return statement\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    test_stimuli : numpy array with shape (n, m)\n",
    "        n stimuli, each with m features, to be classified (i.e. \n",
    "        compute P(A|x) for each x)\n",
    "    exemplars : numpy array with shape (k, m)\n",
    "        k exemplars, each with m features\n",
    "    exemplar_categories : numpy string array with shape (k,)\n",
    "        Categories for the k exemplars. You can assume the values of \n",
    "        exemplar_categories will always be either be \"A\" or \"B\".\n",
    "    theta : (optional) float\n",
    "        A parameter to pass to the similarity function.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    numpy array with shape (n,) such that the i^th element \n",
    "    corresponds to P(A|test_stimuli[i])\n",
    "        \n",
    "    \"\"\"\n",
    "    a_exemplars, b_exemplars = [], []\n",
    "    a1, b1 = [], []\n",
    "    n = 0\n",
    "    final = []\n",
    "    for ex in exemplar_categories:\n",
    "        if ex == \"A\":\n",
    "            a_exemplars.append(exemplars[n])\n",
    "            n = n+1\n",
    "        if ex == \"B\":\n",
    "            b_exemplars.append(exemplars[n])\n",
    "            n = n+1\n",
    "    for stim in test_stimuli:\n",
    "        for a_ex in a_exemplars:\n",
    "            a1.append(calculate_similarity(stim, a_ex, theta))\n",
    "        for b_ex in b_exemplars:\n",
    "            b1.append(calculate_similarity(stim, b_ex, theta))\n",
    "        final.append(sum(a1) / (sum(a1) + sum(b1)))\n",
    "        a1.clear()\n",
    "        b1.clear()\n",
    "    return np.array(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# add your own test cases here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "950efa4032f63d14935717df248b4b2c",
     "grade": true,
     "grade_id": "test_context_model",
     "locked": false,
     "points": 1.75,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Check that the context model is correct.\"\"\"\n",
    "\n",
    "# check that output has the correct shape and is always probabilties\n",
    "for i in range(100):\n",
    "    n, m, k = np.random.randint(2, 10, size=(3,))\n",
    "    test_stimuli = np.random.choice(np.array([1, 0]), size=(n,m))\n",
    "    test_exemplars = np.random.choice(np.array([1, 0]), size=(k,m))\n",
    "    test_exemplar_categories = np.append(np.random.choice([\"A\", \"B\"], size=(k-2,)), [\"A\", \"B\"])\n",
    "    ps = context_model(test_stimuli, test_exemplars, test_exemplar_categories)\n",
    "    \n",
    "    assert ps.shape == (n,)\n",
    "    assert ((ps >= 0) & (ps <= 1)).all()\n",
    "\n",
    "# check that output is exactly right for a small example\n",
    "test_stimuli = np.array([[1, 0, 1], [0, 1, 1], [1, 1, 1]])\n",
    "test_exemplars = np.array([[1, 1, 0], [0, 0, 1], [0, 0, 0], [1, 0, 0]])\n",
    "test_exemplar_categories = np.array([\"B\", \"A\", \"A\", \"A\"])\n",
    "assert_allclose(\n",
    "    context_model(test_stimuli, test_exemplars, test_exemplar_categories),\n",
    "    np.array([ 0.95454545,  0.91735537,  0.17355372]))\n",
    "assert_allclose(\n",
    "    context_model(test_stimuli, test_exemplars, test_exemplar_categories, theta=0.2),\n",
    "    np.array([ 0.91666667,  0.86111111,  0.30555556]))\n",
    "\n",
    "# check that output is exactly right for a larger example\n",
    "test_stimuli = np.array([\n",
    "    [1, 1, 1, 1, 0],\n",
    "    [0, 0, 1, 1, 0],\n",
    "    [1, 0, 0, 1, 1],\n",
    "    [1, 1, 0, 1, 1]])\n",
    "test_exemplars = np.array([\n",
    "    [0, 0, 1, 0, 1],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [1, 0, 0, 0, 1],\n",
    "    [0, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 0, 0],\n",
    "    [1, 0, 0, 1, 1]])\n",
    "test_exemplar_categories = np.array(['B', 'A', 'B', 'B', 'B', 'A'])\n",
    "assert_allclose(\n",
    "    context_model(test_stimuli, test_exemplars, test_exemplar_categories),\n",
    "    np.array([ 0.97868217,  0.32465445,  0.900018  ,  0.9009009 ]))\n",
    "assert_allclose(\n",
    "    context_model(test_stimuli, test_exemplars, test_exemplar_categories, theta=0.5),\n",
    "    np.array([ 0.625     ,  0.32258065,  0.53125   ,  0.57142857]))\n",
    "\n",
    "# check that it uses calculate_similarity\n",
    "old_calculate_similarity = calculate_similarity\n",
    "del calculate_similarity\n",
    "try:\n",
    "    context_model(test_stimuli, test_exemplars, test_exemplar_categories)\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"context_model does not call the calculate_similarity function\")\n",
    "finally:\n",
    "    calculate_similarity = old_calculate_similarity\n",
    "    del old_calculate_similarity\n",
    "    \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "\n",
    "## Context Model: Part C (0.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Now that you have an implementation of the context model, let's try it out! First, let's see how well it does at categorizing the [exemplars that we already have](#exemplars):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "da1ed2c45d5c5d2262574a1c357e8dd5",
     "grade": false,
     "grade_id": "exemplars",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "safe_exemplars = np.array([\n",
    "    [0, 1, 1, 0], # circle / small / blue / solid\n",
    "    [1, 0, 1, 0], # square / big   / blue / solid\n",
    "    [1, 1, 0, 0], # square / small / red  / solid\n",
    "    [1, 1, 1, 1]  # square / small / blue / textured\n",
    "])\n",
    "unsafe_exemplars = np.array([\n",
    "    [1, 1, 0, 1], # square / small / red  / textured\n",
    "    [0, 0, 0, 1], # circle / big   / red  / textured\n",
    "    [0, 1, 1, 1], # circle / small / blue / textured\n",
    "    [0, 1, 0, 0]  # circle / small / red  / solid\n",
    "])\n",
    "all_exemplars = np.vstack([safe_exemplars, unsafe_exemplars])\n",
    "exemplar_categories = np.array([\"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"B\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a250cf02b856312d738c1df018b17f99",
     "grade": false,
     "grade_id": "context_model_exemplars",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.83603896,  0.99613153,  0.83603896,  0.83603896,  0.16396104,\n",
       "        0.00386847,  0.16396104,  0.16396104])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_model(all_exemplars, all_exemplars, exemplar_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Describe how well the context model does at categorizing the known exemplars. Does it give a higher value for $P(A|\\mathbf{x})$ for those $\\mathbf{x}$ which are actually in category $A$? (**0.5 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e3283cc37aa7f95508da3e2b8c3ff69e",
     "grade": true,
     "grade_id": "context_model_part_c",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "The context model does a very good job at categorizing the exemplars. It gives a much higher probability value for the x's that are in category A (the safe ones), and gives a much smaller probability value for the 'unsafe' cateogory B exemplars. Using this, the context model could very accurately categorize between safe and unsafe buttons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "\n",
    "## Context Model: Part D (0.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "A young Botonan is strolling through the city, when a flash of blue and red is seen coming from an alleyway. Taking a closer look, the youngster discovers four buttons never before encountered:\n",
    "<a name=\"novel\"></a>\n",
    "\n",
    "![](images/novel.png)\n",
    "\n",
    "As a Botonan, this youngster feels a strong urge to push the buttons. However, the possibility that some of the buttons might be dangerous demands restraint. The Botonan pauses and takes a closer look.\n",
    "\n",
    "Let's see what the context model says about how likely these buttons are to be dangerous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8d38522078912c176dfccb80ddeda1e0",
     "grade": false,
     "grade_id": "novel_stimuli",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "novel_stimuli = np.array([\n",
    "    [0, 0, 0, 0], # circle / big   / red  / solid\n",
    "    [1, 0, 0, 1], # square / big   / red  / textured\n",
    "    [1, 0, 1, 1], # square / big   / blue / textured\n",
    "    [0, 0, 1, 0]  # circle / big   / blue / solid\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ce20365830cd81be253dde86fa2a6699",
     "grade": false,
     "grade_id": "context_model_novel_stimuli",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12968548,  0.12968548,  0.87031452,  0.87031452])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_model(novel_stimuli, all_exemplars, exemplar_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">In words, what does the context model say? Which of these buttons are more likely to belong to category A (safe buttons)? (**0.25 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "292a19386e9054afef9ce14acaa9282f",
     "grade": true,
     "grade_id": "context_model_part_d_1",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "The context model says that the first two red buttons are unsafe (and should belong to category B), and the second two blue buttons are safe (and should belong to category A). This is because the first two have a low probability of being safe $P(A|\\mathbf{x}) = 0.12 $, and the second two have a higher probability of being safe $P(A|\\mathbf{x}) = 0.87 $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">If the context model is an accurate model of how Botonans categorize concepts, do you think they would push any of the buttons? (**0.25 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5607e51996ef317ce0f0632991128cb9",
     "grade": true,
     "grade_id": "context_model_part_d_2",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Yes, they would likely push the two blue buttons because the probability that they are safe is around the range of other known safe buttons in category A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "## Prototype Model: Part A (0.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "You also know of another model of categorization: the prototype model. This model is similar to the context model, but rather than comparing the new stimulus to all of the exemplars, it compares the new stimulus to the category *prototypes*. How do we know what the category prototype is? Recall from the last problem set that we can compute a prototype from a set of exemplars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Complete the following `prototype` function (it is fine if you reuse your code from the last problem set--- but make sure that it actually works as expected!).</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d6a00dadbf1ad9c096a79323dac1d631",
     "grade": false,
     "grade_id": "prototype",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def prototype(features):\n",
    "    \"\"\"\n",
    "    Compute the prototype features, based on the given features of\n",
    "    category members. The prototype should have a feature if half or\n",
    "    more of the category members have that feature.\n",
    "\n",
    "    Hint: you can use your implementation of `prototype` from the\n",
    "    last problem set here, though you may want to cast the array to \n",
    "    integers to match the format elsewhere (try `.astype(int)`).\n",
    "    \n",
    "    Your solution can be done in 1 line of code (including the return \n",
    "    statement).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    features : numpy array with shape (n, m)\n",
    "        The first dimension corresponds to n category members, and the\n",
    "        second dimension to m features.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    numpy array with shape (m,) corresponding to the features\n",
    "    of the prototype of the category members\n",
    "    \n",
    "    \"\"\"\n",
    "    #reuse code from Ps2\n",
    "    proto = []\n",
    "    lst = []\n",
    "    proto.append(np.mean(features, axis = 0))\n",
    "    for p in proto[0]:\n",
    "        if p >= 0.5:\n",
    "            lst.append(True)\n",
    "        else:\n",
    "            lst.append(False)\n",
    "    return np.array(lst).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# add your own test cases here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3424f5ae29fa1c5e09adb4b795f127c7",
     "grade": true,
     "grade_id": "test_prototype",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test the prototype function.\"\"\"\n",
    "from nose.tools import assert_equal\n",
    "from numpy.testing import assert_array_equal\n",
    "\n",
    "# make sure they get features that are half or more\n",
    "assert_array_equal(prototype(np.array([[0, 1], [0, 0]])), np.array([0, 1]))\n",
    "\n",
    "for i in range(10):\n",
    "    # create a random array of features\n",
    "    n, m = np.random.randint(10, 100, 2)\n",
    "    features = np.random.randint(0, 2, (n, m))\n",
    "    \n",
    "    # compute the prototype\n",
    "    proto = prototype(features)\n",
    "    \n",
    "    # check the shape and type\n",
    "    assert_equal(proto.shape, (m,), \"incorrect shape for the prototype array\")\n",
    "    \n",
    "    # check that the prototype is correct\n",
    "    for j in range(m):\n",
    "        count = features[:, j].sum()\n",
    "        if count >= (n / 2) and not proto[j]:\n",
    "            raise AssertionError(\"prototype should have feature {}, but it doesn't\".format(j))\n",
    "        elif count < (n / 2) and proto[j]:\n",
    "            raise AssertionError(\"prototype should NOT have feature {}, but it does\".format(j))\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<a name=\"prototypes\"></a>Check what your function returns for the \"safe button\" prototype and the \"unsafe button\" prototype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7dbae3e6a285d80a28e01efc1f40349c",
     "grade": false,
     "grade_id": "prototypes",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safe button prototype: [1 1 1 0]\n",
      "Unsafe button prototype: [0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "safe_prototype = prototype(safe_exemplars)\n",
    "unsafe_prototype = prototype(unsafe_exemplars)\n",
    "print(\"Safe button prototype: {}\".format(safe_prototype))\n",
    "print(\"Unsafe button prototype: {}\".format(unsafe_prototype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Describe in words what the features of each prototype are (e.g., \"the safe button prototype is a [size], [color], [fill] [shape]\"). Remember that the first feature corresponds to shape, the second feature corresponds to size, the third feature corresponds to color, and the fourth feature corresponds to fill. (**0.25 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ad0861b070ce222a4c99810d30984168",
     "grade": true,
     "grade_id": "prototype_part_a",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "The safe button prototype corresponds to: square, small, blue, solid. The unsafe button prototype corresponds to: circle, small, red, textured. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "\n",
    "## Prototype Model: Part B (1.75 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Now that we have a way of computing prototypes from our exemplars, let's take a look at the actual prototype model.\n",
    "\n",
    "<a name=\"eq:prototype\"></a>\n",
    "> The prototype model can be described by the following equation:\n",
    ">\n",
    "> $$\n",
    "P(A|\\mathbf{x})=\\frac{\\mathbb{S}(\\mathbf{x}, \\mathbf{\\mu}_A)}{\\mathbb{S}(\\mathbf{x}, \\mathbf{\\mu}_A) + \\mathbb{S}(\\mathbf{x}, \\mathbf{\\mu}_B)}\n",
    "$$\n",
    ">\n",
    "> where $\\mathbb{S}$ is the [similarity function defined above](#eq:similarity), $\\mathbf{x}$ is the novel stimulus, $\\mathbf{\\mu}_A$ is the prototype of category $A$, and $\\mathbf{\\mu}_B$ is the prototype of category $B$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Using your `calculate_similarity` function and your `prototype` function, complete the function `prototype_model` below to implement the [prototype model equation](#eq:prototype).</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4651a98b2961132f9e078f991930bded",
     "grade": false,
     "grade_id": "prototype_model",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def prototype_model(test_stimuli, exemplars, exemplar_categories, theta=0.1):\n",
    "    \"\"\"Computes the probability that each test stimulus belongs to \n",
    "    category A.\n",
    "    \n",
    "    Note: your solution can be done in 8 lines of code, including\n",
    "    the return statement.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_stimuli : numpy array with shape (n, m)\n",
    "        n stimuli, each with m features, to be classified (i.e. \n",
    "        compute P(A|x) for each x)\n",
    "    exemplars : numpy array with shape (k, m)\n",
    "        k exemplars, each with m features\n",
    "    exemplar_categories : numpy string array with shape (k,)\n",
    "        Categories for the k exemplars. You can assume the values of \n",
    "        exemplar_categories will always be either be \"A\" or \"B\".\n",
    "    theta : (optional) float\n",
    "        A parameter to pass to the similarity function. If theta is not\n",
    "        specified, it defaults to 0.1.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    numpy array with shape (n,) such that the i^th element \n",
    "    corresponds to P(A|test_stimuli[i])\n",
    "        \n",
    "    \"\"\"\n",
    "    prob = []\n",
    "    a_exemplars, b_exemplars = [], []\n",
    "    n = 0\n",
    "    for ex in exemplar_categories:\n",
    "        if ex == \"A\":\n",
    "            a_exemplars.append(exemplars[n])\n",
    "            n = n+1\n",
    "        if ex == \"B\":\n",
    "            b_exemplars.append(exemplars[n])\n",
    "            n = n+1\n",
    "    proto_a = prototype(a_exemplars)\n",
    "    proto_b = prototype(b_exemplars)\n",
    "    for stim in test_stimuli:\n",
    "        sim_a = calculate_similarity(stim, proto_a, theta)\n",
    "        sim_b = calculate_similarity(stim, proto_b, theta)\n",
    "        prob.append(sim_a / (sim_a + sim_b))\n",
    "    return np.array(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# add your own test cases here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "41cf87f8d58a37b4f2aaab397f844b44",
     "grade": true,
     "grade_id": "test_prototype_model",
     "locked": false,
     "points": 1.75,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Check that the prototype model is correct.\"\"\"\n",
    "\n",
    "# check that output has the correct shape and is always probabilties\n",
    "for i in range(100):\n",
    "    n, m, k = np.random.randint(2, 10, size=(3,))\n",
    "    test_stimuli = np.random.choice(np.array([1, 0]), size=(n,m))\n",
    "    test_exemplars = np.random.choice(np.array([1, 0]), size=(k,m))\n",
    "    test_exemplar_categories = np.append(np.random.choice([\"A\", \"B\"], size=(k-2,)), [\"A\", \"B\"])\n",
    "    ps = prototype_model(test_stimuli, test_exemplars, test_exemplar_categories)\n",
    "    \n",
    "    assert ps.shape == (n,)\n",
    "    assert ((ps >= 0) & (ps <= 1)).all()\n",
    "\n",
    "# check that output is exactly right for a small example\n",
    "test_stimuli = np.array([[1, 0, 1], [0, 1, 1], [1, 1, 1]])\n",
    "test_exemplars = np.array([[1, 1, 0], [0, 0, 1], [0, 0, 0], [1, 0, 0]])\n",
    "test_exemplar_categories = np.array([\"B\", \"A\", \"A\", \"A\"])\n",
    "assert_allclose(\n",
    "    prototype_model(test_stimuli, test_exemplars, test_exemplar_categories),\n",
    "    np.array([ 0.5       ,  0.5       ,  0.00990099]))\n",
    "assert_allclose(\n",
    "    prototype_model(test_stimuli, test_exemplars, test_exemplar_categories, theta=0.2),\n",
    "    np.array([ 0.5       ,  0.5       ,  0.03846154]))\n",
    "\n",
    "# check that output is exactly right for a larger example\n",
    "test_stimuli = np.array([\n",
    "    [1, 1, 1, 1, 0],\n",
    "    [0, 0, 1, 1, 0],\n",
    "    [1, 0, 0, 1, 1],\n",
    "    [1, 1, 0, 1, 1]])\n",
    "test_exemplars = np.array([\n",
    "    [0, 0, 1, 0, 1],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [1, 0, 0, 0, 1],\n",
    "    [0, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 0, 0],\n",
    "    [1, 0, 0, 1, 1]])\n",
    "test_exemplar_categories = np.array(['B', 'A', 'B', 'B', 'B', 'A'])\n",
    "assert_allclose(\n",
    "    prototype_model(test_stimuli, test_exemplars, test_exemplar_categories),\n",
    "    np.array([ 0.999001  ,  0.09090909,  0.90909091,  0.999001  ]))\n",
    "assert_allclose(\n",
    "    prototype_model(test_stimuli, test_exemplars, test_exemplar_categories, theta=0.5),\n",
    "    np.array([ 0.88888889,  0.33333333,  0.66666667,  0.88888889]))\n",
    "\n",
    "# check that it uses calculate_similarity\n",
    "old_calculate_similarity = calculate_similarity\n",
    "del calculate_similarity\n",
    "try:\n",
    "    prototype_model(test_stimuli, test_exemplars, test_exemplar_categories)\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"prototype_model does not call the calculate_similarity function\")\n",
    "finally:\n",
    "    calculate_similarity = old_calculate_similarity\n",
    "    del old_calculate_similarity\n",
    "    \n",
    "# check that it uses prototype\n",
    "old_prototype = prototype\n",
    "del prototype\n",
    "try:\n",
    "    prototype_model(test_stimuli, test_exemplars, test_exemplar_categories)\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"prototype_model does not call the prototype function\")\n",
    "finally:\n",
    "    prototype = old_prototype\n",
    "    del old_prototype\n",
    "    \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "\n",
    "## Prototype Model: Part C (0.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Let's see how well the prototype model does at categorizing the prototypes of safe and unsafe buttons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c70dfe4b5fec0bfef36244c092da1095",
     "grade": false,
     "grade_id": "prototype_model_prototypes",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.999001,  0.000999])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prototypes = np.vstack([safe_prototype, unsafe_prototype])\n",
    "prototype_model(prototypes, all_exemplars, exemplar_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">How well does it do? Does it classify the safe prototype as safe, and the unsafe prototype as unsafe? (**0.5 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fd3d85c708ba66cfd5024894c9ee37bd",
     "grade": true,
     "grade_id": "prototype_part_c",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "The prototype does extremely well at classifying the safe prototypes as safe and the unsafe prototypes as unsafe. It classsifies the safe buttons being in category A with a probability of 0.999, and the unsafe buttons being in category A with 0.0009 probability (they are therefore category B / unsafe buttons). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "\n",
    "## Prototype Model: Part D (0.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Now let's see what the prototype model would say about the [unknown buttons](#novel) that our young Botonan has encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "67fb759baa91c2dccbe0deec412b5de8",
     "grade": false,
     "grade_id": "prototype_model_novel_stimuli",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09090909,  0.09090909,  0.90909091,  0.90909091])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prototype_model(novel_stimuli, all_exemplars, exemplar_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">What does the prototype model say? Which of these buttons are more likely to belong to category A (safe buttons)? (**0.25 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d66ec0870c1f6b9218cbb1761a7fede3",
     "grade": true,
     "grade_id": "prototype_part_d_1",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "It says the first two red buttons are extremely unlikely to belong to category A, because $P(A|\\mathbf{x}) = 0.0909$ for the two buttons, and are very likely to be unsafe. Therefore, the second two blue buttons (both with $P(A|\\mathbf{x}) = 0.9090$) are much more likely to belong to category A, and thus must be the safe buttons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">What does the prototype model say? Which of these buttons are more likely to belong to category A (safe buttons)? If the prototype model is an accurate model of how Botonans categorize concepts, do you think they would push any of the buttons? (**0.25 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2479a3e0df31f8f0be3e894d37b488a3",
     "grade": true,
     "grade_id": "prototype_part_d_2",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "The prototype model says that the first two buttons are unsafe to push, and the second two are highly likely to be safe. The Botonans would likely push the second two because there is a 90% chance they will be correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "## Comparing Models: Part A (0.75 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "As we develop computational models of cognition, it is not enough to look at a single model and declare that it is good or bad. What is it good or bad in relation to? We must always *compare* our models, in order to get a better sense of how the space of models behave on a particular type of problem.\n",
    "\n",
    "We have now analyzed the context model and prototype model independently, but we have not compared them. First, let's compare how they both behave on the exemplars that have already been observed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0f7a04a1868c626309012331c4173a3a",
     "grade": false,
     "grade_id": "comparing_exemplars",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context model on exemplars:    [ 0.83603896  0.99613153  0.83603896  0.83603896  0.16396104  0.00386847\n",
      "  0.16396104  0.16396104]\n",
      "Prototype model on exemplars:  [ 0.90909091  0.999001    0.90909091  0.90909091  0.09090909  0.000999\n",
      "  0.09090909  0.09090909]\n",
      "True exemplar categories:      ['A' 'A' 'A' 'A' 'B' 'B' 'B' 'B']\n"
     ]
    }
   ],
   "source": [
    "print(\"Context model on exemplars:    {}\".format(context_model(all_exemplars, all_exemplars, exemplar_categories)))\n",
    "print(\"Prototype model on exemplars:  {}\".format(prototype_model(all_exemplars, all_exemplars, exemplar_categories)))\n",
    "print(\"True exemplar categories:      {}\".format(exemplar_categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Which model is more accurate at predicting the exemplar categories? (**0.25 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "01a957659a6ae6f0307be85126630216",
     "grade": true,
     "grade_id": "comparing_part_a_1",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "The prototype model is more accurate at prediciting the exemplar categories because the probability is higher than the context model when it is in category A, as well as lower when it is in category B. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Even though the models have seen these exemplars, and know their true categories, they do not predict the category labels with 100% certainty. Why is this the case? (**0.5 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a170ba17662980f57450ec9aec61dae8",
     "grade": true,
     "grade_id": "comparing_part_a_2",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "These models do not predict the category labels with 100% certainty because for the context model, they must compare them to all of the examplars that belong in each category -- and even if the exemplar is in the category, it is still compared to other ones -- which may have different features than this one, therfore never being able to reach 100% certainty. For the prototype model, the model is comparing the exemplar to the prototype of the category, and thus may have a few matching features but not all, because the prototype is based off if the features are in 50% of the exemplars. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "\n",
    "## Comparing Models: Part B (0.75 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Now let's take a look at how well the models perform on the prototypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bcbb16fbc14de466a97d2fbcdee86952",
     "grade": false,
     "grade_id": "comparing_prototypes",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context model on prototypes:    [ 0.93001628  0.06998372]\n",
      "Prototype model on prototypes:  [ 0.999001  0.000999]\n",
      "True prototype categories:      ['A' 'B']\n"
     ]
    }
   ],
   "source": [
    "print(\"Context model on prototypes:    {}\".format(context_model(prototypes, all_exemplars, exemplar_categories)))\n",
    "print(\"Prototype model on prototypes:  {}\".format(prototype_model(prototypes, all_exemplars, exemplar_categories)))\n",
    "print(\"True prototype categories:      {}\".format(np.array([\"A\", \"B\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Which model is more accurate at predicting the prototypes? Why? (**0.75 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "37ca19498a5826f2a9fbb36721d4bca7",
     "grade": true,
     "grade_id": "comparing_part_b",
     "locked": false,
     "points": 0.75,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "The Prototype model is more accurate at predicting the prototypes. This is because in the probability function of this model, it calculates the similarity of each novel stimulus to the prototype of categories A and B. Therfore, it emits a much more accurate way of predicting the prototypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "## Comparing Models: Part C (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Finally, let's take a look at how the models predict the novel stimuli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d2e8068a4a1fb1099ccd1259e4bb037d",
     "grade": false,
     "grade_id": "comparing_novel_stimuli",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context model on novel:   [ 0.12968548  0.12968548  0.87031452  0.87031452]\n",
      "Prototype model on novel: [ 0.09090909  0.09090909  0.90909091  0.90909091]\n"
     ]
    }
   ],
   "source": [
    "print(\"Context model on novel:   {}\".format(context_model(novel_stimuli, all_exemplars, exemplar_categories)))\n",
    "print(\"Prototype model on novel: {}\".format(prototype_model(novel_stimuli, all_exemplars, exemplar_categories)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">If the true categories of the novel stimuli were $[B, B, B, A]$, which model would be more advantageous in this scenario (remember that category $B$ is the unsafe buttons)? Explain your answer. (**0.5 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "389ac48071c4e0018c073fcccbaebac1",
     "grade": true,
     "grade_id": "comparing_part_c_1",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "If the true categories were $[B, B, B, A]$, I believe the context model would be more advantageous than the Prototype model. This is because on the third novel simulus, since the true category is B, the context model predicts it will be less likeley to be in category A than in B, so it predicts it to be in category with around a 3% more accruate evaluation than the prototype model. Therefore, since it predicts the third novel stimuli to be more unsafe than the prototype model, it would be more advantageous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">If the true categories of the novel stimuli were $[B, B, A, A]$? Explain your answer. (**0.5 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "25c963f61b6f0132dcd35156795d9070",
     "grade": true,
     "grade_id": "comparing_part_c_2",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "If the true categories were $[B, B, A, A]$, the prototype model would be more advantageous than the context model because it ranks the first two (unsafe) buttons with lower probability (3% less) that they would be in category A, meaning they are more unsafe (category B), which corresponds to the first two true categories (B,B). In addition, it ranks the last two (safe) buttons with a higher probability (3% more) than the context model that they would be safe (category A), which corresponds to the last two true categories (A,A)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "## Comparing Models: Part D (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\"> Participants in experiments are better (more accurate and/or faster) at classifying a prototype of previously seen stimuli than classifying new stimuli generated from that prototype: an effect called the **prototype effect**. Would the context / exemplar model be able to account for this effect in people? Why is it that the context / exemplar model can/cannot explain this effect? (**0.5 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "69b1c026d9a11b3ea6cf77b59f1802ab",
     "grade": true,
     "grade_id": "comparing_part_d_1",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "The context model would not be able to account for this effect because it would be slower due to the process of comparing the new exemplar to all the exemplars in the category. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\"> Would the prototype model be able to account for this effect in people? Why is it that the prototype model can/cannot explain this effect? (**0.5 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1f067ad41fb858871d7a85e12ee69876",
     "grade": true,
     "grade_id": "comparing_part_d_2",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Yes, the prototype model would be able to account for the prototype effect because it is comparing the new exemplar to the prototype which it has already created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "Before turning this problem in remember to do the following steps:\n",
    "\n",
    "1. **Restart the kernel** (Kernel$\\rightarrow$Restart)\n",
    "2. **Run all cells** (Cell$\\rightarrow$Run All)\n",
    "3. **Save** (File$\\rightarrow$Save and Checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "source": [
    "<div class=\"alert alert-danger\">After you have completed these three steps, ensure that the following cell has printed \"No errors\". If it has <b>not</b> printed \"No errors\", then your code has a bug in it and has thrown an error! Make sure you fix this error before turning in your problem set.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors!\n"
     ]
    }
   ],
   "source": [
    "print(\"No errors!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
