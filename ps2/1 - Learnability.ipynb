{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "source": [
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "outputs": [],
   "source": [
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "We discussed various approaches to learnability in class. In this problem you will explore some of their implications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Part A (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">In order to prove his theorem, Gold made several assumptions about language and learning. Identify one assumption that **differs** from how language is actually learned. Explain why you chose your answers. (**0.5 points**) </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a313e1f7ed0f485045722097d04db284",
     "grade": true,
     "grade_id": "part_a_1",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "One assumption in Gold's theorem that differs with how language is actually learned is that the language showed to the learner is only a set of *posititve examples*. This assumption differs from how language is learned because when we learn a language we are not just given perfectly grammatical sentences (positive examples). Language is actually learned by taking in the positive examples, as well as negative examples and using the negative ones to reinforce the positive ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">List one assumption about language and learning that Gold made that seems **similar** to the way language is actually learned. (**0.5 points **)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "72d51900c31909220c67c54cbee15161",
     "grade": true,
     "grade_id": "part_a_2",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "One assumption Gold makes that seems similar to the way language is actually learned is that a language is constituted of a set of grammatical senteces. This seems like a reasonable assumption because it makes intuitive sense, and is a very useful model for trying to understand and build upon because in order to learn a language, you need to construct your set of grammatical sentences that you can employ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Part B (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Probably Approximately Correct (PAC) learning makes different assumptions about language learnability. Identify one assumption that differs between PAC learning and Gold's Theorem. (**0.5 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7302d061edbdb41c0ac12c0ec1f810ee",
     "grade": true,
     "grade_id": "part_b_1",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "In PAC learning, the learner differs because it does not have to make a correct guess every time (like in Gold's Theorem): the learner just make correct guesses *most* of the time (ideally with a high probability). To say that a language can be perfectly learned from Gold's Theorem means that a learner needs to be correct every time and never change the guess in the limit. However for PAC learning, the learner is *not* only given positive examples and just needs to be right to the certain degree to say that it performs 'well enough' (by increasing probability through decreasing error rate). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Does the assumption you noted above PAC analysis more or less similar to the way humans learn language? Explain your answer. (**0.5 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ac892305f28c1e78b366014c1b91af14",
     "grade": true,
     "grade_id": "part_b_2",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "It is more similar to the way that humans learn langauge, because we learn language by making mistakes and decreasing our error rate over time. Even when a human has obviously learned a language, they still make mistakes, so PAC encompasses a more reasonable approach by stating that if the learner knows it well enough to a degree—then they have learned the langauge— and do not have to be correct every single time as Gold stated. It also seems much more efficient to learn in this method because we do not have to rely on a massive memory store for all the positive examples of the language. In this way, PAC seems very similar to how humans learn language because we can't ever be 100% sure about anything -- just 99.9999% -- which seems effective enough for a definition of what learning in humans is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "Before turning this problem in remember to do the following steps:\n",
    "\n",
    "1. **Restart the kernel** (Kernel$\\rightarrow$Restart)\n",
    "2. **Run all cells** (Cell$\\rightarrow$Run All)\n",
    "3. **Save** (File$\\rightarrow$Save and Checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "source": [
    "<div class=\"alert alert-danger\">After you have completed these three steps, ensure that the following cell has printed \"No errors\". If it has <b>not</b> printed \"No errors\", then your code has a bug in it and has thrown an error! Make sure you fix this error before turning in your problem set.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors!\n"
     ]
    }
   ],
   "source": [
    "print(\"No errors!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
